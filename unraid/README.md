# üè† AI Town - Template Unraid

Template officiel pour installer AI Town sur Unraid via Community Applications.

## üöÄ Installation

### Via Community Applications (Recommand√©)

1. **Installer Community Applications** (si pas d√©j√† fait)
   - Aller dans `Apps` ‚Üí `Install Community Applications`

2. **Ajouter le template personnalis√©**
   - Aller dans `Docker` ‚Üí `Add Container`
   - Dans `Template repositories`, ajouter :
     ```
     https://raw.githubusercontent.com/Lingelo/ai-town/main/unraid/ai-town.xml
     ```

3. **Installer AI Town**
   - Rechercher "AI Town" dans Community Applications
   - Cliquer sur `Install`

### Installation manuelle

1. **T√©l√©charger le template**
   ```bash
   wget https://raw.githubusercontent.com/Lingelo/ai-town/main/unraid/ai-town.xml
   ```

2. **Placer le template** dans :
   ```
   /boot/config/plugins/dockerMan/templates-user/ai-town.xml
   ```

3. **Red√©marrer** le service Docker ou red√©marrer Unraid

## ‚öôÔ∏è Configuration

### Param√®tres essentiels

| Param√®tre | Description | Valeur par d√©faut |
|-----------|-------------|-------------------|
| **Port WebUI** | Port d'acc√®s √† l'interface | `8080` |
| **Language** | Langue de l'interface | `fr` |
| **LLM Provider** | Fournisseur IA | `openrouter` |
| **OpenRouter API Key** | Cl√© API OpenRouter | _(vide)_ |

### Configuration OpenRouter (Recommand√©)

1. **Cr√©er un compte** sur [OpenRouter.ai](https://openrouter.ai/)
2. **G√©n√©rer une cl√© API** dans les param√®tres
3. **Configurer dans Unraid** :
   - `LLM Provider` : `openrouter`
   - `OpenRouter API Key` : `sk-or-v1-...`
   - `OpenRouter Model` : `anthropic/claude-3.5-sonnet`

### Configuration Ollama (Local)

Pour utiliser un serveur Ollama local ou distant :

1. **Configurer dans Unraid** :
   - `LLM Provider` : `ollama`
   - `Ollama Host` : `http://192.168.1.100:11434`
   - `Ollama Model` : `llama3.1:latest`

## üåç Support multilingue

L'application supporte 3 langues :

- **Fran√ßais** : `VITE_LANGUAGE=fr`
- **Anglais** : `VITE_LANGUAGE=en`  
- **Portugais** : `VITE_LANGUAGE=pt`

## üë®‚Äçüë©‚Äçüëß Personnages personnalis√©s

### Personnages par d√©faut

- **Angelo** - P√®re de famille, passionn√© de technologie
- **M√©lanie** - M√®re de famille, cr√©ative et sociale
- **Jenna** - Fille de 2 ans, curieuse et √©nergique

### Personnaliser les personnages

1. **Cr√©er un fichier** `characters.json` personnalis√©
2. **Mapper le fichier** dans le container :
   ```
   Chemin h√¥te : /mnt/user/appdata/ai-town/characters.json
   Chemin container : /usr/share/nginx/html/config/characters.json
   ```

### Format du fichier characters.json

```json
{
  "characters": {
    "fr": [
      {
        "name": "MonPersonnage",
        "character": "f1",
        "identity": "Description du personnage...",
        "plan": "Objectifs et motivations..."
      }
    ]
  }
}
```

## üîß Configuration avanc√©e

### Variables d'environnement compl√®tes

| Variable | Description | D√©faut |
|----------|-------------|--------|
| `VITE_LANGUAGE` | Langue interface (en/fr/pt) | `fr` |
| `VITE_CONVEX_URL` | URL backend Convex | _(auto)_ |
| `LLM_PROVIDER` | Fournisseur LLM | `openrouter` |
| `OPENROUTER_API_KEY` | Cl√© API OpenRouter | _(vide)_ |
| `OPENROUTER_CHAT_MODEL` | Mod√®le OpenRouter | `anthropic/claude-3.5-sonnet` |
| `OLLAMA_HOST` | Serveur Ollama | _(vide)_ |
| `OLLAMA_MODEL` | Mod√®le Ollama | `llama3.1:latest` |
| `OPENAI_API_KEY` | Cl√© API OpenAI | _(vide)_ |

### Volumes optionnels

| Volume h√¥te | Volume container | Description |
|-------------|------------------|-------------|
| `/mnt/user/appdata/ai-town/characters.json` | `/usr/share/nginx/html/config/characters.json` | Personnages personnalis√©s |
| `/mnt/user/appdata/ai-town/translations/` | `/usr/share/nginx/html/config/translations/` | Traductions personnalis√©es |

## üè• Monitoring et sant√©

### Health Check automatique

Le container inclut un health check automatique :
- **Intervalle** : 30 secondes
- **Timeout** : 3 secondes  
- **Retries** : 3 tentatives

### V√©rification manuelle

```bash
# Status du container
docker ps | grep ai-town

# Logs du container
docker logs ai-town

# Test de l'interface web
curl -I http://[IP-UNRAID]:8080
```

## üõ†Ô∏è D√©pannage

### Probl√®mes courants

**Container ne d√©marre pas**
```bash
# V√©rifier les logs
docker logs ai-town

# V√©rifier la configuration
docker inspect ai-town
```

**Interface web inaccessible**
- V√©rifier que le port n'est pas utilis√© par une autre application
- V√©rifier les r√®gles de firewall d'Unraid
- Tester avec `curl -I http://localhost:8080`

**Erreurs LLM**
- V√©rifier la validit√© de la cl√© API
- Contr√¥ler la connectivit√© r√©seau
- Consulter les logs du container

**Personnages ne se chargent pas**
- V√©rifier le format JSON du fichier characters.json
- Contr√¥ler les permissions du fichier
- V√©rifier que le volume est correctement mont√©

### Reset complet

```bash
# Arr√™ter le container
docker stop ai-town

# Supprimer le container
docker rm ai-town

# Supprimer l'image (optionnel)
docker rmi lingelo/ai-town:latest

# R√©installer depuis Community Applications
```

## üìä Estimation des co√ªts

### OpenRouter (usage mod√©r√©)
- **Claude 3.5 Sonnet** : ~$0.10-0.50/heure
- **GPT-4** : ~$0.20-1.00/heure
- **Llama 3.1** : ~$0.05-0.20/heure

### Ollama (local)
- **Co√ªt** : Gratuit (utilise les ressources locales)
- **Consommation** : ~2-8GB RAM selon le mod√®le

## ü§ù Support et communaut√©

- **Documentation** : [GitHub AI Town](https://github.com/Lingelo/ai-town)
- **Issues** : [GitHub Issues](https://github.com/Lingelo/ai-town/issues)
- **Forum Unraid** : Rechercher "AI Town"
- **Docker Hub** : [lingelo/ai-town](https://hub.docker.com/r/lingelo/ai-town)

## üìÑ Licence

MIT License - Voir [LICENSE](https://github.com/Lingelo/ai-town/blob/main/LICENSE)