version: '3.8'

services:
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.prod
      args:
        - VITE_LANGUAGE=${VITE_LANGUAGE:-en}
        - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434}
        - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
        - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-mxbai-embed-large}
    ports:
      - '${FRONTEND_PORT:-80}:80'
    networks:
      - ai-town-network
    depends_on:
      backend:
        condition: service_healthy

  backend:
    image: ghcr.io/get-convex/convex-backend:latest
    ports:
      - '${PORT:-3210}:3210'
      - '${SITE_PROXY_PORT:-3211}:3211'
    volumes:
      - data:/convex/data
    environment:
      - INSTANCE_NAME=${INSTANCE_NAME:-}
      - INSTANCE_SECRET=${INSTANCE_SECRET:-}
      - CONVEX_RELEASE_VERSION_DEV=${CONVEX_RELEASE_VERSION_DEV:-}
      - ACTIONS_USER_TIMEOUT_SECS=${ACTIONS_USER_TIMEOUT_SECS:-}
      - CONVEX_CLOUD_ORIGIN=${URL_BASE:-http://127.0.0.1}:${PORT:-3210}
      - CONVEX_SITE_ORIGIN=${URL_BASE:-http://127.0.0.1}:${SITE_PROXY_PORT:-3211}
      - DATABASE_URL=${DATABASE_URL:-}
    healthcheck:
      test: curl -f http://localhost:3210/version
      interval: 5s
      start_period: 5s
    networks:
      - ai-town-network

  dashboard:
    image: ghcr.io/get-convex/convex-dashboard:latest
    ports:
      - '${DASHBOARD_PORT:-6791}:6791'
    environment:
      - NEXT_PUBLIC_DEPLOYMENT_URL=http://127.0.0.1:${PORT:-3210}
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - ai-town-network

volumes:
  data:

networks:
  ai-town-network:
    driver: bridge